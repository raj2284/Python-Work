{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pract- 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the IRIS dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with linear kernel: 1.0\n",
      "Accuracy with poly kernel: 1.0\n",
      "Accuracy with rbf kernel: 1.0\n",
      "Accuracy with sigmoid kernel: 0.3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of kernels to test\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "accuracies = []\n",
    "\n",
    "# Train and evaluate SVM for each kernel\n",
    "for kernel in kernels:\n",
    "    svm_classifier = SVC(kernel=kernel)\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Accuracy with {kernel} kernel: {accuracy}\")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(kernels, accuracies, color='lightgreen')\n",
    "plt.title(\"Accuracy Comparison for Different SVM Kernels\")\n",
    "plt.xlabel(\"Kernel\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pract - 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load country data (example: a CSV file with columns like 'Country', 'GDP', 'Population')\n",
    "country_data = pd.read_csv('country_data.csv')  # Replace with your file path\n",
    "\n",
    "# Extract relevant features for clustering\n",
    "X = country_data[['GDP', 'Population']]  # Select features relevant to clustering\n",
    "\n",
    "# Implement K-Means with 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Add cluster labels to the data\n",
    "country_data['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='GDP', y='Population', hue='Cluster', data=country_data, palette='viridis')\n",
    "plt.title('K-Means Clustering of Country Data')\n",
    "plt.xlabel('GDP')\n",
    "plt.ylabel('Population')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Implement Agglomerative Clustering with 3 clusters\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=3)\n",
    "country_data['Agglomerative_Cluster'] = agg_clustering.fit_predict(X)\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='GDP', y='Population', hue='Agglomerative_Cluster', data=country_data, palette='coolwarm')\n",
    "plt.title('Agglomerative Clustering of Country Data')\n",
    "plt.xlabel('GDP')\n",
    "plt.ylabel('Population')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pract - 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MLwork\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5482 - loss: 0.9826 - val_accuracy: 0.5000 - val_loss: 0.9385\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7802 - loss: 0.8088 - val_accuracy: 0.8333 - val_loss: 0.8122\n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8002 - loss: 0.7101 - val_accuracy: 0.8750 - val_loss: 0.7180\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8676 - loss: 0.5713 - val_accuracy: 0.8333 - val_loss: 0.6360\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.5262 - val_accuracy: 0.8333 - val_loss: 0.5729\n",
      "Epoch 6/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.4474 - val_accuracy: 0.8333 - val_loss: 0.5256\n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.4344 - val_accuracy: 0.8333 - val_loss: 0.4832\n",
      "Epoch 8/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8462 - loss: 0.3954 - val_accuracy: 0.8750 - val_loss: 0.4463\n",
      "Epoch 9/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8374 - loss: 0.3363 - val_accuracy: 0.8750 - val_loss: 0.4193\n",
      "Epoch 10/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7455 - loss: 0.3968 - val_accuracy: 0.8750 - val_loss: 0.4082\n",
      "Epoch 11/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.3117 - val_accuracy: 0.9167 - val_loss: 0.3902\n",
      "Epoch 12/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2947 - val_accuracy: 0.9167 - val_loss: 0.3725\n",
      "Epoch 13/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8818 - loss: 0.2524 - val_accuracy: 0.9167 - val_loss: 0.3668\n",
      "Epoch 14/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8766 - loss: 0.2659 - val_accuracy: 0.9167 - val_loss: 0.3492\n",
      "Epoch 15/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8965 - loss: 0.2969 - val_accuracy: 0.9583 - val_loss: 0.3479\n",
      "Epoch 16/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9160 - loss: 0.2786 - val_accuracy: 0.9583 - val_loss: 0.3301\n",
      "Epoch 17/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9216 - loss: 0.2276 - val_accuracy: 0.9583 - val_loss: 0.3060\n",
      "Epoch 18/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9135 - loss: 0.2503 - val_accuracy: 0.9583 - val_loss: 0.3114\n",
      "Epoch 19/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9310 - loss: 0.2019 - val_accuracy: 0.9583 - val_loss: 0.2914\n",
      "Epoch 20/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9512 - loss: 0.1824 - val_accuracy: 0.9583 - val_loss: 0.2954\n",
      "Epoch 21/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9580 - loss: 0.1767 - val_accuracy: 0.9583 - val_loss: 0.2669\n",
      "Epoch 22/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9546 - loss: 0.1491 - val_accuracy: 0.9167 - val_loss: 0.3011\n",
      "Epoch 23/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9054 - loss: 0.1882 - val_accuracy: 0.9583 - val_loss: 0.2739\n",
      "Epoch 24/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9762 - loss: 0.1120 - val_accuracy: 0.9583 - val_loss: 0.2584\n",
      "Epoch 25/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.1169 - val_accuracy: 0.9167 - val_loss: 0.2947\n",
      "Epoch 26/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9582 - loss: 0.1301 - val_accuracy: 0.9583 - val_loss: 0.2547\n",
      "Epoch 27/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9682 - loss: 0.1176 - val_accuracy: 0.9167 - val_loss: 0.2717\n",
      "Epoch 28/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.1290 - val_accuracy: 0.9167 - val_loss: 0.2739\n",
      "Epoch 29/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9765 - loss: 0.1158 - val_accuracy: 0.9583 - val_loss: 0.2547\n",
      "Epoch 30/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9748 - loss: 0.0836 - val_accuracy: 0.9167 - val_loss: 0.2448\n",
      "Epoch 31/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9580 - loss: 0.0730 - val_accuracy: 0.9167 - val_loss: 0.2808\n",
      "Epoch 32/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9614 - loss: 0.1019 - val_accuracy: 0.9167 - val_loss: 0.2611\n",
      "Epoch 33/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9697 - loss: 0.1062 - val_accuracy: 0.9167 - val_loss: 0.2584\n",
      "Epoch 34/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.0704 - val_accuracy: 0.9167 - val_loss: 0.2680\n",
      "Epoch 35/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9878 - loss: 0.0869 - val_accuracy: 0.9167 - val_loss: 0.2780\n",
      "Epoch 36/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0738 - val_accuracy: 0.9583 - val_loss: 0.2421\n",
      "Epoch 37/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1143 - val_accuracy: 0.9583 - val_loss: 0.2569\n",
      "Epoch 38/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9545 - loss: 0.0811 - val_accuracy: 0.9167 - val_loss: 0.2675\n",
      "Epoch 39/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.0603 - val_accuracy: 0.9167 - val_loss: 0.2673\n",
      "Epoch 40/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0767 - val_accuracy: 0.9167 - val_loss: 0.3010\n",
      "Epoch 41/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0634 - val_accuracy: 0.9167 - val_loss: 0.2815\n",
      "Epoch 42/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9671 - loss: 0.0604 - val_accuracy: 0.9583 - val_loss: 0.2560\n",
      "Epoch 43/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.0922 - val_accuracy: 0.9167 - val_loss: 0.2788\n",
      "Epoch 44/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0617 - val_accuracy: 0.9167 - val_loss: 0.2696\n",
      "Epoch 45/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0457 - val_accuracy: 0.9167 - val_loss: 0.2758\n",
      "Epoch 46/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9708 - loss: 0.0754 - val_accuracy: 0.9167 - val_loss: 0.2869\n",
      "Epoch 47/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0609 - val_accuracy: 0.9167 - val_loss: 0.2647\n",
      "Epoch 48/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.0789 - val_accuracy: 0.9167 - val_loss: 0.3073\n",
      "Epoch 49/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9733 - loss: 0.0671 - val_accuracy: 0.9167 - val_loss: 0.2787\n",
      "Epoch 50/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0737 - val_accuracy: 0.9583 - val_loss: 0.2551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.0471\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Task - 1\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load the IRIS dataset\n",
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "iris.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "iris['class'] = label_encoder.fit_transform(iris['class'])\n",
    "\n",
    "# Split data\n",
    "X = iris.drop('class', axis=1)\n",
    "y = iris['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create ANN model\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')  # 3 output neurons for 3 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.4654 - val_accuracy: 0.9557 - val_loss: 0.1504\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9628 - loss: 0.1251 - val_accuracy: 0.9667 - val_loss: 0.1145\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9756 - loss: 0.0783 - val_accuracy: 0.9703 - val_loss: 0.0975\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0596 - val_accuracy: 0.9688 - val_loss: 0.1043\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0429 - val_accuracy: 0.9696 - val_loss: 0.1029\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0343 - val_accuracy: 0.9744 - val_loss: 0.1005\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0288 - val_accuracy: 0.9730 - val_loss: 0.1000\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0232 - val_accuracy: 0.9706 - val_loss: 0.1212\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.0178 - val_accuracy: 0.9742 - val_loss: 0.1046\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0165 - val_accuracy: 0.9699 - val_loss: 0.1343\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9691 - loss: 0.1340\n",
      "Test Accuracy: 0.9728999733924866\n"
     ]
    }
   ],
   "source": [
    "# Task -2\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 28*28) / 255.0  # Flatten and normalize\n",
    "X_test = X_test.reshape(-1, 28*28) / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Create ANN model\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(28*28,), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # 10 output neurons for 10 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2us/step\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MLwork\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 50ms/step - accuracy: 0.7012 - loss: 0.5289 - val_accuracy: 0.8536 - val_loss: 0.3347\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.9753 - loss: 0.0771 - val_accuracy: 0.8438 - val_loss: 0.4756\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.9977 - loss: 0.0097 - val_accuracy: 0.8472 - val_loss: 0.6181\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 47ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.8442 - val_loss: 0.6625\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.7577e-04 - val_accuracy: 0.8466 - val_loss: 0.7104\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8435 - loss: 0.6895\n",
      "Test Accuracy: 0.8445199728012085\n"
     ]
    }
   ],
   "source": [
    "# Task-3\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Flatten\n",
    "\n",
    "# Load and preprocess data\n",
    "max_features = 10000  # Vocabulary size\n",
    "max_len = 200  # Maximum review length\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "\n",
    "# Create ANN model\n",
    "model = Sequential([\n",
    "    Embedding(max_features, 128, input_length=max_len),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pract -9 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MLwork\\.venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.9048 - loss: 0.3153 - val_accuracy: 0.9848 - val_loss: 0.0515\n",
      "Epoch 2/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9847 - loss: 0.0492 - val_accuracy: 0.9880 - val_loss: 0.0403\n",
      "Epoch 3/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9903 - loss: 0.0310 - val_accuracy: 0.9920 - val_loss: 0.0319\n",
      "Epoch 4/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 0.0214 - val_accuracy: 0.9897 - val_loss: 0.0400\n",
      "Epoch 5/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.0150 - val_accuracy: 0.9895 - val_loss: 0.0388\n",
      "Epoch 6/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0102 - val_accuracy: 0.9903 - val_loss: 0.0364\n",
      "Epoch 7/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0076 - val_accuracy: 0.9917 - val_loss: 0.0412\n",
      "Epoch 8/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0067 - val_accuracy: 0.9922 - val_loss: 0.0382\n",
      "Epoch 9/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.9918 - val_loss: 0.0445\n",
      "Epoch 10/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0047 - val_accuracy: 0.9897 - val_loss: 0.0582\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0585\n",
      "Test Accuracy: 0.9902999997138977\n"
     ]
    }
   ],
   "source": [
    "# Task-1\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 28, 28, 1) / 255.0  # Normalize and reshape\n",
    "X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Create CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9700 images belonging to 5 classes.\n",
      "Found 100 images belonging to 5 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MLwork\\.venv\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 33/304\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 431ms/step - accuracy: 0.2277 - loss: 291.4297"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m     17\u001b[0m     Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m     18\u001b[0m     MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     Dense(\u001b[38;5;28mlen\u001b[39m(train_data\u001b[38;5;241m.\u001b[39mclass_indices), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m ])\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 27\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     30\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_data)\n",
      "File \u001b[1;32md:\\MLwork\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\MLwork\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32md:\\MLwork\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\MLwork\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\MLwork\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\MLwork\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MLwork\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\MLwork\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32md:\\MLwork\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32md:\\MLwork\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32md:\\MLwork\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Task-2 \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Path to the training and testing directories\n",
    "train_dir = 'D:/MLwork/.venv/ML_LAB/Fruits Classification/train'\n",
    "test_dir = 'D:/MLwork/.venv/ML_LAB/Fruits Classification/test'\n",
    "\n",
    "# Data generators without pre-processing\n",
    "train_gen = ImageDataGenerator()\n",
    "test_gen = ImageDataGenerator()\n",
    "\n",
    "train_data = train_gen.flow_from_directory(train_dir, target_size=(100, 100), batch_size=32, class_mode='categorical')\n",
    "test_data = test_gen.flow_from_directory(test_dir, target_size=(100, 100), batch_size=32, class_mode='categorical')\n",
    "\n",
    "# Create CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(train_data.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_data, epochs=10, validation_data=test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pract-1\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 151ms/step - accuracy: 0.5909 - loss: 0.6636 - val_accuracy: 0.5804 - val_loss: 0.6632\n",
      "Epoch 2/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 112ms/step - accuracy: 0.5789 - loss: 0.6895 - val_accuracy: 0.6636 - val_loss: 0.6011\n",
      "Epoch 3/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 114ms/step - accuracy: 0.7267 - loss: 0.5429 - val_accuracy: 0.7850 - val_loss: 0.4750\n",
      "Epoch 4/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 116ms/step - accuracy: 0.7833 - loss: 0.4765 - val_accuracy: 0.6805 - val_loss: 0.5832\n",
      "Epoch 5/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 114ms/step - accuracy: 0.7545 - loss: 0.5053 - val_accuracy: 0.7928 - val_loss: 0.4660\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.7913 - loss: 0.4692\n",
      "Test Accuracy: 0.7928400039672852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Predicted sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 1. Load the IMDB dataset\n",
    "max_features = 10000  # Limit the vocabulary size\n",
    "maxlen = 500  # Maximum length of input sequences\n",
    "\n",
    "# Load the dataset, only keeping the most frequent words\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Pad sequences to ensure uniform input length\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "# Convert labels to categorical (0 = negative, 1 = positive)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "# 2. Build the RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer to map words to dense vectors\n",
    "model.add(Embedding(input_dim=max_features, output_dim=128, input_length=maxlen))\n",
    "\n",
    "# Simple RNN layer (the Recurrent part)\n",
    "model.add(SimpleRNN(64, return_sequences=False))\n",
    "\n",
    "# Dropout to prevent overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer (binary classification)\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# 3. Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 4. Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# 5. Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# 6. Making Predictions (Example)\n",
    "# Predict sentiment of a sample review\n",
    "sample_review = X_test[0:1]  # You can replace this with your own test review\n",
    "prediction = model.predict(sample_review)\n",
    "predicted_class = 'positive' if prediction[0][1] > prediction[0][0] else 'negative'\n",
    "print(f\"Predicted sentiment: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
